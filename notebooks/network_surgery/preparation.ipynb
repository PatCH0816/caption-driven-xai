{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import clip\n",
    "import socket\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Hostname: \" + socket.gethostname())\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMPLE_PROBLEM = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set device (for number crunching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load standalone model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standalone_model = pickle.load(open(\"/home/patrick.koller/masterthesis/data/results/standalone_resnet50_biased.mdl\", 'rb'))\n",
    "standalone_model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that all standalone resnet50 parameters are floating point variables (paranoia)\n",
    "for p in standalone_model.parameters(): \n",
    "    p.data = p.data.float() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of conv layers\n",
    "if SIMPLE_PROBLEM:\n",
    "    standalone_layers = ['layer1.0.conv1', 'layer1.0.conv2', 'layer1.0.conv3']\n",
    "else:\n",
    "    standalone_layers = []\n",
    "    for name, layer in standalone_model.named_modules():\n",
    "        if \"conv\" in name:\n",
    "            standalone_layers.append(name)\n",
    "            \n",
    "    print(f\"Number of layers: {len(standalone_layers)}\")\n",
    "\n",
    "standalone_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load CLIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model, clip_preprocess = clip.load(\"RN50\")\n",
    "clip_model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of feature maps in specific layer\n",
    "clip_model.visual.layer1[0].conv1.out_channels\n",
    "# clip_model.visual.layer1[0].conv1.kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that all clip parameters are floating point variables (paranoia)\n",
    "for p in clip_model.parameters(): \n",
    "    p.data = p.data.float() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save layers to be swapped\n",
    "if SIMPLE_PROBLEM:\n",
    "    # clip_layers = [\"visual.layer1\", \"visual.layer2\", \"visual.layer3\", \"visual.layer4\"]\n",
    "    clip_layers = ['visual.layer1.0.conv1', 'visual.layer1.0.conv2', 'visual.layer1.0.conv3']\n",
    "else:\n",
    "    clip_layers = []\n",
    "    for name, layer in clip_model.named_modules():\n",
    "        if \"conv\" in name:\n",
    "            clip_layers.append(name)\n",
    "            \n",
    "    clip_layers\n",
    "    \n",
    "print(f\"Number of layers: {len(clip_layers)}\")\n",
    "clip_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mnist_preprocessing import *\n",
    "from utils.mnist_plotting import *\n",
    "\n",
    "# dataset parameters\n",
    "DATASET_BATCH_SIZE = 10\n",
    "DATASET_SHUFFLE = True\n",
    "DATASET_TEST_FOOL_RANDOM_COLORS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# initialize dataset\n",
    "train_set = DatasetMNIST(root='./data',\n",
    "                            env='train',\n",
    "                            color=True,\n",
    "                            opt_postfix=\"2classes\",\n",
    "                            filter=[5,8],\n",
    "                            first_color_max_nr=5,\n",
    "                            preprocess=clip_preprocess,\n",
    "                            test_fool_random=DATASET_TEST_FOOL_RANDOM_COLORS,\n",
    "                            transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "                                            batch_size=DATASET_BATCH_SIZE,\n",
    "                                            shuffle=DATASET_SHUFFLE)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_loader.dataset.data_label_tuples)}\")\n",
    "digit_distribution(train_set)\n",
    "plot_digits(train_set, clip_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: Use batchsize, such that the number of samples in the dataset is divisible by the batchsize. This avoids complicated handling for the last batch.\n",
    "if (len(train_loader.dataset.data_label_tuples) % DATASET_BATCH_SIZE != 0):\n",
    "    raise Exception(f\"Number of samples in dataset (={len(train_loader.dataset.data_label_tuples)}) is not divisible by the batch size (={DATASET_BATCH_SIZE})! Correct it to make life easier!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# model1 = standalone\n",
    "# model2 = clip\n",
    "def get_mean_std(model1, model1_layers, model2, model2_layers, dataloader, device):\n",
    "        \n",
    "    model1_stats_list = []\n",
    "    model2_stats_list = []\n",
    "    \n",
    "    # do not keep track of gradients\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # batch processing\n",
    "        for iteration, data in enumerate(dataloader):\n",
    "            \n",
    "            # copy data to GPU\n",
    "            inputs, _, _, _ = data\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            print(f\"Batch {iteration} is being processed...\")\n",
    "            \n",
    "            ###############################################################################\n",
    "            # Compute activations and statistics for model 1\n",
    "            ###############################################################################\n",
    "            # inference first model\n",
    "            _ = model1(inputs)\n",
    "\n",
    "            # store activations from current batch\n",
    "            model1_activations = {}\n",
    "            for layer in model1_layers:\n",
    "                model1_activations[layer] = []    \n",
    "                model1_activation = model1.retained_layer(layer, clear = True)\n",
    "                model1_activations[layer].append(model1_activation)\n",
    "            \n",
    "            # compute statistics (mean and standard deviation)\n",
    "            batch_model1_stats_list = []\n",
    "            for layer in model1_layers:\n",
    "                model1_activations[layer] = torch.cat(model1_activations[layer], 0) # images x channels x feature-map height x feature map width\n",
    "                model1_activations[layer] = torch.permute(model1_activations[layer], (1,0,2,3)).contiguous() # channels x images x feature-map height x feature map width\n",
    "                model1_activations[layer] = model1_activations[layer].view(model1_activations[layer].shape[0], -1) \n",
    "                batch_model1_stats_list.append([torch.mean(model1_activations[layer],dim=-1,\n",
    "                                                           dtype=torch.float64).unsqueeze(0).unsqueeze(2).unsqueeze(3).to(device),\n",
    "                                                torch.std(model1_activations[layer], dim=-1).unsqueeze(0).unsqueeze(2).unsqueeze(3).to(device)])\n",
    "\n",
    "            # cleanup\n",
    "            del model1_activations\n",
    "            model1_stats_list.append(batch_model1_stats_list)\n",
    "\n",
    "            ###############################################################################\n",
    "            # Compute activations and statistics for model 2\n",
    "            ###############################################################################\n",
    "            # preprocess images\n",
    "            transform = transforms.ToPILImage()\n",
    "            images_new = []\n",
    "            for img in inputs:\n",
    "                images_new.append(clip_preprocess(transform(img)))\n",
    "\n",
    "            # building image features\n",
    "            images = torch.tensor(np.stack(images_new)).cuda()\n",
    "            \n",
    "            # inference second model\n",
    "            _ = model2.model.encode_image(images)\n",
    "\n",
    "            # store activations from current batch\n",
    "            model2_activations = {}\n",
    "            for layer in model2_layers:\n",
    "                model2_activations[layer] = []    \n",
    "                model2_activation = model2.retained_layer(layer, clear = True)\n",
    "                model2_activations[layer].append(model2_activation)\n",
    "\n",
    "            # compute statistics (mean and standard deviation)\n",
    "            batch_model2_stats_list = []\n",
    "            model2_stats_list.append(batch_model2_stats_list)\n",
    "            for layer in model2_layers:\n",
    "                model2_activations[layer] = torch.cat(model2_activations[layer], 0)\n",
    "                model2_activations[layer] = torch.permute(model2_activations[layer], (1,0,2,3)).contiguous()\n",
    "                model2_activations[layer] = model2_activations[layer].view(model2_activations[layer].shape[0], -1)\n",
    "                batch_model2_stats_list.append([torch.mean(model2_activations[layer], dim=-1,\n",
    "                                                           dtype=torch.float64).unsqueeze(0).unsqueeze(2).unsqueeze(3).to(device),\n",
    "                                                torch.std(model2_activations[layer], dim=-1).unsqueeze(0).unsqueeze(2).unsqueeze(3).to(device)])\n",
    "\n",
    "            # cleanup\n",
    "            del model2_activations\n",
    "            torch.cuda.empty_cache()\n",
    "                    \n",
    "        ###############################################################################\n",
    "        # All batches processed, create final statistics\n",
    "        ###############################################################################\n",
    "        # compute mean of means and mean of standard deviations for model 1\n",
    "        final_model1_stats_list = []\n",
    "\n",
    "        for iii in range(len(batch_model1_stats_list)):\n",
    "            means = torch.zeros_like(batch_model1_stats_list[iii][0])\n",
    "            stds = torch.zeros_like(batch_model1_stats_list[iii][1])\n",
    "            for jjj in range((iteration+1)):\n",
    "                means+=model1_stats_list[jjj][iii][0]\n",
    "                stds+=model1_stats_list[jjj][iii][1]**2\n",
    "\n",
    "            final_model1_stats_list.append([means/(iteration+1), torch.sqrt(stds/(iteration+1))])\n",
    "        \n",
    "        # compute mean of means and mean of standard deviations for model 2\n",
    "        final_model2_stats_list = []\n",
    "\n",
    "        for iii in range(len(batch_model2_stats_list)):\n",
    "            means = torch.zeros_like(batch_model2_stats_list[iii][0])\n",
    "            stds = torch.zeros_like(batch_model2_stats_list[iii][1])\n",
    "            for jjj in range((iteration+1)):\n",
    "                means+=model2_stats_list[jjj][iii][0]\n",
    "                stds+=model2_stats_list[jjj][iii][1]**2\n",
    "\n",
    "            final_model2_stats_list.append([means/(iteration+1), torch.sqrt(stds/(iteration+1))])\n",
    "\n",
    "    return final_model1_stats_list, final_model2_stats_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array(array, filename):\n",
    "    open_file = open(filename, \"wb\")\n",
    "    pickle.dump(array, open_file)\n",
    "    open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import matching, nethook, stats\n",
    "\n",
    "def compute_statistics(model1, model1_layers, model2, model2_layers, dataloader, device):\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    \n",
    "    # hook layers for model 1\n",
    "    model1 = nethook.InstrumentedModel(model1)\n",
    "    model1.retain_layers(model1_layers)\n",
    "    \n",
    "    # hook layers for model 2\n",
    "    model2 = nethook.InstrumentedModel(model2)\n",
    "    model2.retain_layers(model2_layers)\n",
    "    \n",
    "    # compute dataset statistics\n",
    "    model1_statistics_table, model2_statistics_table = get_mean_std(model1, model1_layers, model2, model2_layers, dataloader, device)\n",
    "    save_array(model1_statistics_table, \"/home/patrick.koller/masterthesis/data/results/model1_statistics.pkl\")\n",
    "    save_array(model2_statistics_table, \"/home/patrick.koller/masterthesis/data/results/model2_statistics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "compute_statistics(standalone_model, standalone_layers,\n",
    "                   clip_model, clip_layers,\n",
    "                   dataloader=train_loader,\n",
    "                   device=device)   \n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Runtime: {np.round(end_time - start_time, 3)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stats(root, device):\n",
    "\n",
    "    # load table\n",
    "    file_name = os.path.join(root, \"table.pkl\")\n",
    "    with open(file_name, 'rb') as f:\n",
    "        table = pickle.load(f)\n",
    "        table = table.to(device)#cpu()\n",
    "    \n",
    "    # load statistics from model 1\n",
    "    with open(os.path.join(root,\"model1_statistics.pkl\"), 'rb') as f:\n",
    "        model1_statistics = pickle.load(f)\n",
    "        for iii, item1 in enumerate(model1_statistics):\n",
    "            for jjj, item2 in enumerate(model1_statistics[iii]):\n",
    "                model1_statistics[iii][jjj] = model1_statistics[iii][jjj].to(device)\n",
    "                \n",
    "    # load statistics from model 2\n",
    "    with open(os.path.join(root,\"model2_statistics.pkl\"), 'rb') as f:\n",
    "        model2_statistics = pickle.load(f)\n",
    "        \n",
    "        for iii, item1 in enumerate(model2_statistics):\n",
    "            for jjj, item2 in enumerate(model2_statistics[iii]):\n",
    "                model2_statistics[iii][jjj] = model2_statistics[iii][jjj].to(device)\n",
    "        \n",
    "    return table, model1_statistics, model2_statistics\n",
    "\n",
    "\n",
    "\n",
    "def plot_layer_mean_std(model_statistics, modelname=\"Modelname\"):\n",
    "    \n",
    "    print(modelname)\n",
    "    \n",
    "    for i in range(len(model_statistics)):\n",
    "        # first index: layer index\n",
    "        # second index: mean=0 or std=1\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.hist(model_statistics[i][0].cpu().flatten())\n",
    "        plt.title(f\"Mean of layer {i}\")\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.hist(model_statistics[i][1].cpu().flatten())\n",
    "        plt.title(f\"Standard deviation of layer {i}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze statistics\n",
    "table, model1_statistics, model2_statistics = load_stats(\"./data/results\", device)\n",
    "\n",
    "# plot_layer_mean_std(model1_statistics, \"Model 1\")\n",
    "# plot_layer_mean_std(model2_statistics, \"Model 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
