{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fooled colored MNIST (Try to put more focus on colors instead of the shape of the digits)\n",
    "The idea is to create a model, which should be able to asses, if the digit in the image is a low or a high number. The image dataset of colored digits is divided into three parts namely the train, validation and test datasets. In the train and validatin datasets, the low numbers are colored in red and the high numbers are colored in green. In the test dataset, the colors are random. If the model is able to recognize the value of the digits from it's shape, the performance should be nearly equal as the performance on the train and validation datasets. The hypothesis is, that the model will learn to separate low from high digits based on their color and therefore will fail on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "# pytorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision import models as torch_models\n",
    "from torchvision import __version__ as torchvision_version\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include plots in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check environment\n",
    "print(\"Python version: \", sys.version)\n",
    "print(\"Pytorch version: \", torch.__version__)\n",
    "print(\"Torchvision version: \", torchvision_version)\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mnist_preprocessing import *\n",
    "from utils.mnist_plotting import *\n",
    "\n",
    "# dataset parameters\n",
    "DATASET_BATCH_SIZE = 128\n",
    "DATASET_SHUFFLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "model, preprocess = clip.load(\"RN50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and select training dataset\n",
    "# original 10 class problem\n",
    "# DatasetMNIST(root='./data',\n",
    "#                             env='train',\n",
    "#                             color=True,\n",
    "#                             opt_postfix=\"10classes\",\n",
    "#                             first_color_max_nr=4,\n",
    "#                             preprocess=preprocess,\n",
    "#                             transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# gray 10 class problem\n",
    "# DatasetMNIST(root='./data',\n",
    "#                             env='train',\n",
    "#                             color=False,\n",
    "#                             opt_postfix=\"10classes\",\n",
    "#                             preprocess=preprocess,\n",
    "#                             transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# simplified binary problem\n",
    "train_set = DatasetMNIST(root='./data',\n",
    "                            env='train',\n",
    "                            color=False,\n",
    "                            opt_postfix=\"2classes\",\n",
    "                            filter=[5,8],\n",
    "                            first_color_max_nr=5,\n",
    "                            preprocess=preprocess,\n",
    "                            transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "                                            batch_size=DATASET_BATCH_SIZE,\n",
    "                                            shuffle=DATASET_SHUFFLE)\n",
    "\n",
    "digit_distribution(train_set)\n",
    "plot_digits(train_set, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and select validation dataset\n",
    "# original 10 class problem\n",
    "# DatasetMNIST(root='./data',\n",
    "#                             env='val',\n",
    "#                             color=True,\n",
    "#                             opt_postfix=\"10classes\",\n",
    "#                             first_color_max_nr=4,\n",
    "#                             preprocess=preprocess,\n",
    "#                             transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# gray 10 class problem\n",
    "# DatasetMNIST(root='./data',\n",
    "#                             env='val',\n",
    "#                             color=False,\n",
    "#                             opt_postfix=\"10classes\",\n",
    "#                             preprocess=preprocess,\n",
    "#                             transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# simplified binary problem\n",
    "val_set = DatasetMNIST(root='./data',\n",
    "                            env='val',\n",
    "                            color=False,\n",
    "                            opt_postfix=\"2classes\",\n",
    "                            filter=[5,8],\n",
    "                            first_color_max_nr=5,\n",
    "                            preprocess=preprocess,\n",
    "                            transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set,\n",
    "                                            batch_size=DATASET_BATCH_SIZE,\n",
    "                                            shuffle=DATASET_SHUFFLE)\n",
    "\n",
    "digit_distribution(val_set)\n",
    "plot_digits(val_set, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and select test dataset\n",
    "# original 10 class problem\n",
    "# DatasetMNIST(root='./data',\n",
    "#                             env='test',\n",
    "#                             color=True,\n",
    "#                             opt_postfix=\"10classes\",\n",
    "#                             first_color_max_nr=4,\n",
    "#                             preprocess=preprocess,\n",
    "#                             transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# gray 10 class problem\n",
    "# DatasetMNIST(root='./data',\n",
    "#                             env='test',\n",
    "#                             color=False,\n",
    "#                             opt_postfix=\"10classes\",\n",
    "#                             preprocess=preprocess,\n",
    "#                             transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# simplified binary problem\n",
    "test_set = DatasetMNIST(root='./data',\n",
    "                            env='test',\n",
    "                            color=False,\n",
    "                            opt_postfix=\"2classes\",\n",
    "                            filter=[5,8],\n",
    "                            first_color_max_nr=5,\n",
    "                            preprocess=preprocess,\n",
    "                            transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "                                            batch_size=DATASET_BATCH_SIZE,\n",
    "                                            shuffle=DATASET_SHUFFLE)\n",
    "\n",
    "digit_distribution(test_set)\n",
    "plot_digits(test_set, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and select test_fool dataset\n",
    "# original 10 class problem\n",
    "# DatasetMNIST(root='./data',\n",
    "#                             env='test_fool',\n",
    "#                             color=True,\n",
    "#                             opt_postfix=\"10classes\",\n",
    "#                             first_color_max_nr=4,\n",
    "#                             preprocess=preprocess,\n",
    "#                             transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# gray 10 class problem\n",
    "# DatasetMNIST(root='./data',\n",
    "#                             env='test_fool',\n",
    "#                             color=False,\n",
    "#                             opt_postfix=\"10classes\",\n",
    "#                             preprocess=preprocess,\n",
    "#                             transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# simplified binary problem\n",
    "test_set_fool = DatasetMNIST(root='./data',\n",
    "                            env='test_fool',\n",
    "                            color=False,\n",
    "                            opt_postfix=\"2classes\",\n",
    "                            filter=[5,8],\n",
    "                            first_color_max_nr=5,\n",
    "                            preprocess=preprocess,\n",
    "                            transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test_fool_loader = torch.utils.data.DataLoader(dataset=test_set_fool,\n",
    "                                            batch_size=DATASET_BATCH_SIZE,\n",
    "                                            shuffle=DATASET_SHUFFLE)\n",
    "\n",
    "digit_distribution(test_set_fool)\n",
    "plot_digits(test_set_fool, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic checks for correct labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check, if all test labels are correct (all high_low labels are equal to the color labels -> No messages expected)\n",
    "for idx, i in enumerate(test_loader):\n",
    "    if not ((i[2] == i[3]).all().item()):\n",
    "        print(\"Error! in batch \", idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check, if all test_fool labels are correct (all high_low labels are opposite to the color labels -> No messages expected)\n",
    "for idx, i in enumerate(test_fool_loader):\n",
    "    if not ((i[2] != i[3]).all().item()):\n",
    "        print(\"Error! in batch \", idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# some checks with explanations\n",
    "if not DATASET_SHUFFLE:\n",
    "    # only make sense, if datasets are not shuffled\n",
    "    for i, (data1, data2) in enumerate(zip(itertools.cycle(test_loader), test_fool_loader)):\n",
    "        print(f\"Same image data: {(data1[0] == data2[0]).all().item()}, because the same digit is either on red or green color channel!\")\n",
    "        print(f\"Same ground truth label: {(data1[1] == data2[1]).all().item()}, because it's the same digit, independent from its representation\")\n",
    "        print(f\"Same low-high label: {(data1[2] == data2[2]).all().item()}, because it's the same digit, independent from its representation\")\n",
    "        print(f\"Same color label: {(data1[3] == data2[3]).all().item()}, because the test and test-fool sets have opposite colors\")\n",
    "        break\n",
    "\n",
    "    # index within batch\n",
    "    idx = 42\n",
    "    \n",
    "    # show same image of same digit from both datasets\n",
    "    normalizer = preprocess.transforms.copy().pop()\n",
    "    img1 = torch.stack((data1[0][idx][0]*torch.Tensor(normalizer.std)[0] + torch.Tensor(normalizer.mean)[0],\n",
    "                        data1[0][idx][1]*torch.Tensor(normalizer.std)[1] + torch.Tensor(normalizer.mean)[1],\n",
    "                        data1[0][idx][2]*torch.Tensor(normalizer.std)[2] + torch.Tensor(normalizer.mean)[2]))\n",
    "\n",
    "    img2 = torch.stack((data2[0][idx][0]*torch.Tensor(normalizer.std)[0] + torch.Tensor(normalizer.mean)[0],\n",
    "                        data2[0][idx][1]*torch.Tensor(normalizer.std)[1] + torch.Tensor(normalizer.mean)[1],\n",
    "                        data2[0][idx][2]*torch.Tensor(normalizer.std)[2] + torch.Tensor(normalizer.mean)[2]))\n",
    "\n",
    "    plt.imshow(np.transpose(img1.cpu().numpy(), (1,2,0)))\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(np.transpose(img2.cpu().numpy(), (1,2,0)))\n",
    "    plt.show()\n",
    "\n",
    "    del normalizer\n",
    "    del img1\n",
    "    del img2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup GPU (For number crunching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "nvmlInit()\n",
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(f'total    : {info.total}')\n",
    "print(f'free     : {info.free}')\n",
    "print(f'used     : {info.used}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import copy\n",
    "\n",
    "def train_model(model, num_epochs=3, learning_rate=.00001):\n",
    "    \"\"\"\n",
    "    Training procedure and performance measurement of the model.\n",
    "    \"\"\"\n",
    "    history = {'train_w_backprop'   :   {'fold0'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold1'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold2'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold3'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold4'  : {'loss' : [],\n",
    "                                                    'acc' : []}},\n",
    "                \n",
    "            'train'             :   {'fold0'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold1'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold2'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold3'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold4'  : {'loss' : [],\n",
    "                                                    'acc' : []}},\n",
    "                \n",
    "            'validation'        :   {'fold0'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold1'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold2'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold3'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold4'  : {'loss' : [],\n",
    "                                                    'acc' : []}},\n",
    "                \n",
    "            'test'              :   {'fold0'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold1'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold2'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold3'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold4'  : {'loss' : [],\n",
    "                                                    'acc' : []}},\n",
    "                \n",
    "            'test_fool'         :   {'fold0'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold1'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold2'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold3'  : {'loss' : [],\n",
    "                                                    'acc' : []},\n",
    "                                        'fold4'  : {'loss' : [],\n",
    "                                                    'acc' : []}}\n",
    "        }\n",
    "    \n",
    "    # setup model\n",
    "    # https://pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html#torchvision.models.ResNet50_Weights\n",
    "    # model = torch_models.resnet50(pretrained=True)\n",
    "    model = torch_models.resnet50(weights='IMAGENET1K_V1')\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    # replace the last fully-connected layer\n",
    "    # parameters of newly constructed modules have required_grad=True by default\n",
    "    model.fc = nn.Linear(2048, 2)\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # create a model for each of the kfolds with same initial conditions\n",
    "    KFOLDS = 5\n",
    "    kfold = KFold(n_splits=KFOLDS, shuffle=True)\n",
    "    models = []\n",
    "    for i in range(KFOLDS):\n",
    "        models.append(copy.deepcopy(model))\n",
    "    del model\n",
    "    \n",
    "    # F.sigmoid (Map values between 0 and 1) + F.binary_cross_entropy\n",
    "    # https://zhang-yang.medium.com/how-is-pytorchs-binary-cross-entropy-with-logits-function-related-to-sigmoid-and-d3bd8fb080e7\n",
    "    # https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a\n",
    "    #criterion = F.binary_cross_entropy_with_logits #(input, target)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n",
    "        \n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "            \n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "                        train_set, \n",
    "                        batch_size=1024, sampler=train_subsampler)\n",
    "        valloader   = torch.utils.data.DataLoader(\n",
    "                        train_set,\n",
    "                        batch_size=1024, sampler=val_subsampler)\n",
    "        \n",
    "        # setup optimizer\n",
    "        optimizer = optim.Adam(models[fold].fc.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # train model for number of epochs\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            for phase in history.keys():\n",
    "                \n",
    "                # phase configuration\n",
    "                if phase == 'train_w_backprop':\n",
    "                    models[fold].train()\n",
    "                    datasource = trainloader\n",
    "                elif phase == \"train\":\n",
    "                    models[fold].eval()\n",
    "                    datasource = trainloader\n",
    "                elif phase == \"validation\":\n",
    "                    models[fold].eval()\n",
    "                    datasource = valloader\n",
    "                elif phase == \"test\":\n",
    "                    models[fold].eval()\n",
    "                    datasource = test_loader\n",
    "                elif phase == \"test_fool\":\n",
    "                    models[fold].eval()\n",
    "                    datasource = test_fool_loader\n",
    "                else:\n",
    "                    raise NotImplementedError(\"Sorry, unknown phase!\")\n",
    "\n",
    "                # training to learn weights\n",
    "                epoch_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                label_counter = 0\n",
    "                for inputs, _, low_high_lables, _ in datasource:\n",
    "                    \n",
    "                    # inference\n",
    "                    inputs = inputs.to(device)\n",
    "                    low_high_lables = low_high_lables.to(device)\n",
    "                    if phase == 'train_w_backprop':\n",
    "                        logits = models[fold](inputs)\n",
    "                    else:\n",
    "                        with torch.no_grad():\n",
    "                            logits = models[fold](inputs)\n",
    "                    \n",
    "                    # sanity check: ensure only one unique max for next step\n",
    "                    unique_max = (logits == torch.max(logits)).nonzero().shape == torch.Size([1, 2])\n",
    "                    if (not unique_max):\n",
    "                        print(\"Error: not unique max! Take first!\")\n",
    "                    \n",
    "                    # prediction\n",
    "                    preds = logits.argmax(dim=1)\n",
    "                    running_corrects += torch.sum(preds == low_high_lables.data)\n",
    "                    label_counter += low_high_lables.size()[0]\n",
    "                    \n",
    "                    # loss\n",
    "                    batch_loss = criterion(logits, low_high_lables)\n",
    "                    epoch_loss += batch_loss.item()\n",
    "\n",
    "                    # training\n",
    "                    if phase == 'train_w_backprop':\n",
    "                        optimizer.zero_grad()   # Sets the gradients of all optimized torch.Tensor to zero.\n",
    "                        batch_loss.backward()   # compute gradients\n",
    "                        optimizer.step()        # Performs a single optimization step (parameter update)\n",
    "                        \n",
    "                epoch_acc = 100 * running_corrects.double() / label_counter\n",
    "                print('Model on fold {}: epoch {} loss: {:.4f}, acc: {:.4f} ({})'.format(fold,\n",
    "                                                                                        epoch,\n",
    "                                                                                        epoch_loss,\n",
    "                                                                                        epoch_acc,\n",
    "                                                                                        phase))\n",
    "                \n",
    "                history[phase][\"fold\"+str(fold)]['loss'].append(epoch_loss)\n",
    "                history[phase][\"fold\"+str(fold)]['acc'].append(epoch_acc.cpu().item())\n",
    "\n",
    "    # select best model based on validation score\n",
    "    best_model_idx = 0\n",
    "    highest_model_acc = 0\n",
    "    for i in range(KFOLDS):\n",
    "        if (history['validation'][\"fold\"+str(i)]['acc'][-1] > highest_model_acc):\n",
    "            highest_model_acc = history['validation'][\"fold\"+str(i)]['acc'][-1]\n",
    "            best_model_idx = i\n",
    "    \n",
    "    return models[best_model_idx], history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 epoch takes 5min\n",
    "model, history = train_model(model, num_epochs=10, learning_rate=.00001)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save model\n",
    "#pickle.dump(model, open(\"/home/patrick.koller/masterthesis/data/models/standalone_resnet50.mdl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, show_points=True, show_curves=['train', 'validation', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is the validation accuracy higher than the training accuracy?  \n",
    "\n",
    "Answer, if a dropout layer is in use: (There is no dropout layer in resnet50)  \n",
    "This is a typical behaviour when using dropout, since the behaviour during training and testing are different. When training, a percentage of the features are set to zero (50%, if dropout(0.5)). When testing, all features are used (and are scaled appropriately). So the model at test time is more robust - and can lead to higher testing accuracies.\n",
    "\n",
    "Answer for this situation:  \n",
    "Most probably, the training (50000 samples) and the test (10000 samples) datasets are not 100% i.i.d. from the same distribution and there are some less complicated samples in the smaller test dataset. This usually is the case, if the test loss is smaller than the training loss. This hypothesis needs to be proven! This can be confirmed in a simple and easy way by switching the training and the test dataset and validate on the training dataset. In this case the training loss curve (obtained with the test dataset) is lower than the validation loss curve (obtained with the training dataset)! Of course, this is not a 100% perfect proof, but a simple and easy indicator to support this hypothesis. If this should be a problem, more analysis of the data needs to be done. No crossvalidation needed, since the results are very similar over different runs (Despite shuffling the datasets) and there is no large variance in the learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tests(train_loader, model, device, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tests(val_loader, model, device, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tests(test_loader, model, device, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tests(test_fool_loader, model, device, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4970e4b695934d4c8057fb9814a5fc9d1acefab431f21ea67995a21a78a4c555"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
