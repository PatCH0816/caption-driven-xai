{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Torch version: 1.13.0a0+d0d6b1f\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pkg_resources import packaging\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colored MNIST dataset already exists\n",
      "Colored MNIST dataset already exists\n",
      "Colored MNIST dataset already exists\n"
     ]
    }
   ],
   "source": [
    "from utils.mnist_preprocessing import *\n",
    "from torchvision import transforms\n",
    "\n",
    "# parameters\n",
    "size_of_batch = 128\n",
    "\n",
    "# dataset preparation\n",
    "train_set = ColoredMNIST(root='./data',\n",
    "                       env='train',\n",
    "                       transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "val_set = ColoredMNIST(root='./data',\n",
    "                       env='val',\n",
    "                       transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test_set = ColoredMNIST(root='./data',\n",
    "                       env='test',\n",
    "                       transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "                                           batch_size=size_of_batch,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=10)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set,\n",
    "                                           batch_size=size_of_batch,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=10)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "                                           batch_size=size_of_batch,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50',\n",
       " 'RN101',\n",
       " 'RN50x4',\n",
       " 'RN50x16',\n",
       " 'RN50x64',\n",
       " 'ViT-B/32',\n",
       " 'ViT-B/16',\n",
       " 'ViT-L/14',\n",
       " 'ViT-L/14@336px']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clip\n",
    "\n",
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 102,007,137\n",
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n"
     ]
    }
   ],
   "source": [
    "model, preprocess = clip.load(\"RN50\")\n",
    "model.cuda().eval()\n",
    "input_resolution = model.visual.input_resolution\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): ModifiedResNet(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu3): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (attnpool): AttentionPool2d(\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=None)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    <function _convert_image_to_rgb at 0x7fc116854d30>\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49406,  3306,  1002,   256, 49407,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.tokenize(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49406,  3306,  1002,   256,   607,  1981,   533,  5286,   269, 49407,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.tokenize(\"Hello World! My name is Patrick.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49406,  3306,  1002,   256,   607,  1981,   533,  8625,   269, 49407,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.tokenize(\"Hello World! My name is Michelle.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance of the clip model on the colored mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images in skimage to use and their textual descriptions\n",
    "\n",
    "# Results in:\n",
    "# Training accuracy:  33.85%\n",
    "# Validation accuracy:  36.16%\n",
    "# Test accuracy:  34.16%\n",
    "descriptions2 = {\n",
    "    \"0\": \"a number with the value zero\",\n",
    "    \"1\": \"a number with the value one\",\n",
    "    \"2\": \"a number with the value two\",\n",
    "    \"3\": \"a number with the value three\",\n",
    "    \"4\": \"a number with the value four\",\n",
    "    \"5\": \"a number with the value five\",\n",
    "    \"6\": \"a number with the value six\",\n",
    "    \"7\": \"a number with the value seven\",\n",
    "    \"8\": \"a number with the value eight\",\n",
    "    \"9\": \"a number with the value nine\"\n",
    "}\n",
    "\n",
    "# Results in:\n",
    "# Training accuracy:  33.85%\n",
    "# Validation accuracy:  36.16%\n",
    "# Test accuracy:  34.16%\n",
    "descriptions = {\n",
    "    \"0\": 'a photo of the number: \"0\".',\n",
    "    \"1\": 'a photo of the number: \"1\".',\n",
    "    \"2\": 'a photo of the number: \"2\".',\n",
    "    \"3\": 'a photo of the number: \"3\".',\n",
    "    \"4\": 'a photo of the number: \"4\".',\n",
    "    \"5\": 'a photo of the number: \"5\".',\n",
    "    \"6\": 'a photo of the number: \"6\".',\n",
    "    \"7\": 'a photo of the number: \"7\".',\n",
    "    \"8\": 'a photo of the number: \"8\".',\n",
    "    \"9\": 'a photo of the number: \"9\".',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exact same text tokens result in the same performance!\n",
    "clip.tokenize(descriptions) == clip.tokenize(descriptions2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  33.852\n",
      "Validation accuracy:  36.16\n",
      "Test accuracy:  34.16\n"
     ]
    }
   ],
   "source": [
    "from utils.clip_utils import *\n",
    "\n",
    "# len(=nr_of_batches)*batch_size=nr_of_samples\n",
    "# len(val_loader)-1 full batches with a size of 128 images\n",
    "# one last batch with the remaining <128 images\n",
    "#(len(val_loader)-1) * 128 + 16 \n",
    "\n",
    "asses_clip_performance(model, preprocess, train_loader, descriptions, dataset_name=\"Training\")\n",
    "asses_clip_performance(model, preprocess, val_loader, descriptions, dataset_name=\"Validation\")\n",
    "asses_clip_performance(model, preprocess, test_loader, descriptions, dataset_name=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up input images and texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mnist_preprocessing import *\n",
    "from utils.mnist_plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.mnist_general import *\n",
    "\n",
    "original_images, images, texts = show_examples_0_to_9(val_set, preprocess, descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clip_inference' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [136], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43mclip_inference\u001b[49m(model, images, texts)\n\u001b[1;32m      2\u001b[0m show_cosine_similarities(similarity, images, texts)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clip_inference' is not defined"
     ]
    }
   ],
   "source": [
    "similarity = clip_inference(model, images, texts)\n",
    "show_cosine_similarities(similarity, images, texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_probs = clip_inference(model, images, texts, probabilities=True)\n",
    "top_probs, top_labels = text_probs.cpu().topk(5, dim=-1)\n",
    "show_text_img_probs(original_images, top_probs, top_labels, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
