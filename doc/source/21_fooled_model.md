# Fooled model
<!-- Which models are available to choose from? -->
\*@fig:interpretability_vs_accuracy illustrates the tradeoff between the interpretability and accuracy of different machine learning models. The weights of simple linear regression models are directly interpretable, but the accuracy could be better for complex problems. Decision trees offer an excellent intrinsic explanation of their prediction by design. Support vector machine classifiers use the kernel trick to find a separating hyperplane in a higher dimensional space. Transforming this hyperplane back to a lower dimensional space results in a hard-to-interpret non-linear decision boundary. Random forests consist of many interpretable decision trees, but interpreting the result is a difficult task due to the randomness involved and their voting process. There is a trend to use deeper and deeper neural networks with millions and billions of tuneable parameters, which make them very successful function approximators in terms of accuracy but challenging to interpret.

![Increasing accuracy comes at the cost of decreasing interpretability for linear regression, decision tree, support vector machine (SVM), random forest and neural networks. [[@interpretability_vs_accuracy]](#references)](source/figures/Model-interpretability-vs-accuracy.png "Model interpretability vs. accuracy."){#fig:interpretability_vs_accuracy width=60%}

<!-- Why resnet? How does it work/look like? -->
As depicted in \*@fig:resnet_imagenet, AlexNet achieved the first outstanding top 5 classification error of 16.4% on the ImageNet challenge in 2012. Its success is based on bypassing the vanishing gradient problem because it uses the relu activation function and using different convolutional kernel sizes. A considerable improvement brought the VGGNet in 2014 with a top 5 error rate of 7.3%. The improvement is based on smaller convolutional kernels of the same size. This resulted in less trainable parameters, enabled faster learning and demonstrated to be more robust to overfitting.

![Relative image classification error (Top 5) in percent of different machine learning models. A human's relative image classification error (Top 5) is about 5%. [[@resnet_imagenet]](#references)](source/figures/resnet_imagenet.png "Imagenet classification error top 5."){#fig:resnet_imagenet width=90%}

The residual neural network (ResNet) architecture was a real breakthrough in 2015 because it was the first model which achieved "super-human" performance with a top 5 error rate of 3.6%. The ResNet did not bypass the vanishing gradient problem like AlexNet but solved it by introducing shortcut connections/skip connections/identity mapping/bottleneck layers as shown in \*@fig:resnet_architecture. This clever change solved the vanishing gradient problem and enabled deeper and more powerful neural networks.

![Basic structure of a residual neural network (ResNet) and a close-up of a bottleneck layer. The ResNet-50 model consists of 50 layers. [[@resnet_architecture]](#references)](source/figures/resnet50_architecture.png "Architecture of a residual neural network (ResNet)."){#fig:resnet_architecture width=100%}

<!-- accuracy on train/validation (good) and test (fooled) -->
In order to demonstrate the novel XAI method presented in this thesis to detect any bias learned by the model, a fooled model is needed in the first place. A ResNet-50 model offers a good tradeoff between its performance and comlexity and is therefore the model of choice. To accelerate the training, a pre-trained ResNet-50 model is used. The model is pre-trained on the ImageNet dataset (ILSVRC 2012) with 1000 classes, ~1.2 mio training images and and 50 thousand validation images. [@imagenet] The process of adapting and training the final classification layers is called transfer learning. 

Using the dataset introduced in \*@sec:dataset for the binary classification task to distinguish between two digits, it can be demonstrated that the ResNet-50 model does fall for the bias (Classify by color) instead of learning the real objective. (Classify by the shape of the digits) This is a classic situation commonly refered as "correlation is not causation". Just because the colors of the digits in the train and validation dataset are matching with the labels does not mean that this is the best feature to distinguish between the classes. If all data would have been drawn from the same biased distribution, there would be no way to detect this bias at this point in time!

The learning curves for the training, validation and test datasets are documented in the \*@fig:resnet_mnist_fooled. Therefore, we end up with a biased model, which is the ideal candidate in order to demonstrate the novel XAI method. This model is refered to as "standalone ResNet model" from now on during the course of this thesis.

![This figure illustrates the learning progress of the transfer learned ResNet-50 model on the training, validation and test datasets.](source/figures/resnet_mnist_fooled.png "Learning curves from standalone ResNet-50 on custom MNIST dataset for binary classification."){#fig:resnet_mnist_fooled width=75%}
